{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks (Classifier evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. The code currently does not perform any train/test splits. Split the data into training, validation, and test sets, via 1/3, 1/3, 1/3 splits. Use random splits of the data (i.e., each should be a random, non- overlapping sample of the data; this can be obtained by first shuffling the data). After training on the training set, report the accuracy of the classifier on the validation and test sets (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(parseDataFromFile(\"beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffle = shuffle(data, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data_shuffle]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:int(len(X)/3)]\n",
    "X_valid = X[int(len(X)/3): int(2*len(X)/3)]\n",
    "X_test = X[int(2*len(X)/3):]\n",
    "y_train = y[:int(len(y)/3)]\n",
    "y_valid = y[int(len(y)/3): int(2*len(y)/3)]\n",
    "y_test = y[int(2*len(y)/3):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta) \n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(theta):\n",
    "  scores = [inner(theta,x) for x in X_train]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a==b) for (a,b) in zip(predictions,y_train)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_valid(theta):\n",
    "  scores = [inner(theta,x) for x in X_valid]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a==b) for (a,b) in zip(predictions,y_valid)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_test(theta):\n",
    "  scores = [inner(theta,x) for x in X_test]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a==b) for (a,b) in zip(predictions,y_test)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy=0.7180656386872263\n"
     ]
    }
   ],
   "source": [
    "#accuracy of the classifier on valid set\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_valid(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy=0.7187856242875142\n"
     ]
    }
   ],
   "source": [
    "#accuracy of the classifier on test set\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_test(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Report the number of Positives, Negatives, True Positives, True Negatives, False Positives, and False Negatives using the test set of the classifier you trained above (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [inner(theta,x) for x in X_test]\n",
    "predictions = [s > 0 for s in scores]\n",
    "correct = [(a==b) for (a,b) in zip(predictions,y_test)]\n",
    "acc = sum(correct) * 1.0 / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12485"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positives\n",
    "positive = sum(predictions)\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4182"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negatives\n",
    "negative = len(predictions) - sum(predictions)\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9089"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True Positive\n",
    "test_positive = [(a==b==1) for (a,b) in zip(predictions,y_test)]\n",
    "true_positive = sum(test_positive)\n",
    "true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3396"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False Positive\n",
    "false_positive = positive - true_positive\n",
    "false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True Negative\n",
    "test_negative = [(a==b==0) for (a,b) in zip(predictions,y_test)]\n",
    "true_negative = sum(test_negative)\n",
    "true_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False Negative\n",
    "false_negative = negative - true_negative\n",
    "false_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. (Hard) Describe how you would modify the code stub provided if you wanted to assign greater importance to False Positives compared to False Negatives. Suggest specific modifications that would make to the code if you wanted to assign 10 times as much importance to False Positives as compared to False Negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### According to the cost function = c1 * y * log(h(theta)) + c2 * (1-y) * log(1-h(theta)), the first part of the equation calculate false positives and the latter part calcualte false negatives. In order to assign greater importance to false positives compared to false negatives, we only need to adjust the coeffecients of c1/c2. If we want to assign 10 times as much importance to false positives as compared to false negatives, we need to time log(10) in the latter part of the equation. So in the def function code above, we should change NEGATIVE Log-likelihood - loglikelihood -= logit * log(10) and change NEGATIVE Derivative of log-likelihood - dl[k] -= X[i][k] * log(10))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Implement a training/validation/test pipeline so that you can select the best model based on its performance on the validation set. Try models with lamda {0, 0.01, 0.1, 1, 100}. Report the performance on the training/validation/test sets for the best value of lamda (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0:\taccuracy=0.7178856422871542\n"
     ]
    }
   ],
   "source": [
    "# When lam = 0, accuracy of the classifier on valid set\n",
    "lam = 0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_valid(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.01:\taccuracy=0.7178256434871303\n"
     ]
    }
   ],
   "source": [
    "# When lam = 0.01, accuracy of the classifier on valid set\n",
    "lam = 0.01\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_valid(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.1:\taccuracy=0.7181256374872502\n"
     ]
    }
   ],
   "source": [
    "# When lam = 0.1, accuracy of the classifier on valid set\n",
    "lam = 0.1\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_valid(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1:\taccuracy=0.7180656386872263\n"
     ]
    }
   ],
   "source": [
    "# When lam = 1, accuracy of the classifier on valid set\n",
    "lam = 1\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_valid(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 100:\taccuracy=0.6723465530689386\n"
     ]
    }
   ],
   "source": [
    "# When lam = 100, accuracy of the classifier on valid set\n",
    "lam = 100\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_valid(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### When try models with lamda {0, 0.01, 0.1, 1, 100}, we find that lamda = 0.1 is the best model becasue it has highest accuracy on validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.1:\taccuracy=0.71906876275051\n"
     ]
    }
   ],
   "source": [
    "# When lam = 0.1, accuracy of the classifier on train set\n",
    "lam = 0.1\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.1:\taccuracy=0.7192056158876823\n"
     ]
    }
   ],
   "source": [
    "# When lam = 0.1, accuracy of the classifier on test set\n",
    "lam = 0.1\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance_test(theta)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting the lamda = 0.01, the performance on the training set is 0.71906876275051, on the validation set is 0.7181256374872502 and on the test set is 0.7192056158876823."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks (Community Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. How many connected components are in the graph, and how many nodes are in the largest connected component (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "Collecting decorator>=4.3.0 (from networkx)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: decorator, networkx\n",
      "Successfully installed decorator-4.3.0 networkx-2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Network visualization ###\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = set()\n",
    "nodes = set()\n",
    "for edge in open('egonet.txt'):\n",
    "  x,y = edge.split()\n",
    "  x,y = int(x),int(y)\n",
    "  edges.add((x,y))\n",
    "  edges.add((y,x))\n",
    "  nodes.add(x)\n",
    "  nodes.add(y)\n",
    "\n",
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "  G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(nx.connected_components(G), key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next we'll implement a `greedy' version of normalized cuts, using just the largest connected component found above. First, split it into two equal halves, just by taking the 50% of nodes with the lowest and 50% with the highest IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. What is the normalized-cut cost of the 50/50 split you found above (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = max(nx.connected_components(G), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = sorted(largest)[:int(len(largest)/2)]\n",
    "high = sorted(largest)[int(len(largest)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_large = set()\n",
    "nodes_large = set()\n",
    "\n",
    "for i in low:\n",
    "    for j in low:\n",
    "        for a in high:\n",
    "            for b in high:\n",
    "                if (i,j) in edges:\n",
    "                    edges_large.add((i,j))\n",
    "                    edges_large.add((j,i))\n",
    "                    nodes_large.add(i)\n",
    "                    nodes_large.add(j)\n",
    "                if(i,a) in edges:\n",
    "                    edges_large.add((i,a))\n",
    "                    edges_large.add((a,i))\n",
    "                    nodes_large.add(i)\n",
    "                    nodes_large.add(a)\n",
    "                if(i,b) in edges:\n",
    "                    edges_large.add((i,b))\n",
    "                    edges_large.add((b,i))\n",
    "                    nodes_large.add(i)\n",
    "                    nodes_large.add(b)\n",
    "                if(j,a) in edges:\n",
    "                    edges_large.add((a,j))\n",
    "                    edges_large.add((j,a))\n",
    "                    nodes_large.add(a)\n",
    "                    nodes_large.add(j)\n",
    "                if(j,b) in edges:\n",
    "                    edges_large.add((b,j))\n",
    "                    edges_large.add((j,b))\n",
    "                    nodes_large.add(b)\n",
    "                    nodes_large.add(j)\n",
    "                if(a,b) in edges:\n",
    "                    edges_large.add((a,b))\n",
    "                    edges_large.add((b,a))\n",
    "                    nodes_large.add(a)\n",
    "                    nodes_large.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = nx.Graph()\n",
    "for e in edges_large:\n",
    "  G_1.add_edge(e[0],e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4224058769513316"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nx.normalized_cut_size(G_1, high, low, weight = 0.5)/2\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we'll implement our greedy algorithm as follows: during each step, we'll move one node from one cluster to the other, choosing whichever move minimizes the resulting normalized cut cost (in case of a tie, pick the node with the lower ID). Repeat this until the cost can't be reduced any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. What are the elements of the split, and what is its normalized cut cost (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = []\n",
    "def abc(low, high):\n",
    "    p = []\n",
    "    q = 0\n",
    "    while q < len(low):\n",
    "        high.append(low[0])\n",
    "        del low[0] \n",
    "        n = nx.normalized_cut_size(G_1, high, low)/2\n",
    "        p.append(n)\n",
    "        q+=1\n",
    "        low.append(high[-1])\n",
    "        del high[-1]\n",
    "    r = 0\n",
    "    while r < len(high):\n",
    "        low.append(high[0])\n",
    "        del high[0] \n",
    "        n = nx.normalized_cut_size(G_1, high, low)/2\n",
    "        p.append(n)\n",
    "        r+=1\n",
    "        high.append(low[-1])\n",
    "        del low[-1]\n",
    "    t = min(p)\n",
    "    x = p.index(t)\n",
    "    u.append(t)\n",
    "    if x < len(low):\n",
    "        high.append(low[x])\n",
    "        del low[x]\n",
    "    if x >= len(low):\n",
    "        low.append(high[x-len(low)])\n",
    "        del high[x+1-len(low)]\n",
    "    return(low,high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09817045961624274\n",
      "([697, 703, 708, 713, 719, 745, 747, 753, 769, 772, 774, 800, 803, 805, 810, 811, 819, 828, 823, 830, 840, 880, 890, 869, 856, 798], [825, 861, 863, 864, 876, 878, 882, 884, 886, 888, 889, 893, 729, 804])\n"
     ]
    }
   ],
   "source": [
    "abc(low,high)\n",
    "for e in range(20):\n",
    "    if len(u) <= 1:\n",
    "        abc(low,high)\n",
    "    else:\n",
    "        if u[e] < u[e-1]:\n",
    "            abc(low,high)\n",
    "        else:\n",
    "            print(u[e-1])\n",
    "            print(abc(low,high))\n",
    "            break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Re-implement your greedy algorithm above so that it maximizes the modularity, rather than the normalized cut cost. Report modularity values for the 50/50 split you find (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = []\n",
    "def fgh(low, high):\n",
    "    p = []\n",
    "    q = 0\n",
    "    while q < len(low):\n",
    "        high.append(low[0])\n",
    "        del low[0] \n",
    "        n = nx.algorithms.community.modularity(G_1,[low,high])\n",
    "        p.append(n)\n",
    "        q+=1\n",
    "        low.append(high[-1])\n",
    "        del high[-1]\n",
    "    r = 0\n",
    "    while r < len(high):\n",
    "        low.append(high[0])\n",
    "        del high[0] \n",
    "        n = nx.algorithms.community.modularity(G_1,[low,high])\n",
    "        p.append(n)\n",
    "        r+=1\n",
    "        high.append(low[-1])\n",
    "        del low[-1]\n",
    "    t = max(p)\n",
    "    x = p.index(t)\n",
    "    u.append(t)\n",
    "    if x < len(low):\n",
    "        high.append(low[x])\n",
    "        del low[x]\n",
    "    if x >= len(low):\n",
    "        low.append(high[x-len(low)])\n",
    "        del high[x+1-len(low)]\n",
    "    return(low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = sorted(largest)[:int(len(largest)/2)]\n",
    "high = sorted(largest)[int(len(largest)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33801652892561973\n"
     ]
    }
   ],
   "source": [
    "fgh(low,high)\n",
    "for e in range(20):\n",
    "    if len(u) <= 1:\n",
    "        fgh(low,high)\n",
    "    else:\n",
    "        if u[e] >= u[e-1]:\n",
    "            fgh(low,high)\n",
    "        else:\n",
    "            print(u[e-1])\n",
    "            break  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
